{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe448ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# STEP 0: PARAMETERS & PATHS (sesuaikan)\n",
    "# ==========================================\n",
    "PROCESSED_DIR = \"../dataset_processed\"  # output: train/ val/ test/ per kelas\n",
    "MODEL_DIR = \"../models\"\n",
    "MODEL_ID = 1\n",
    "\n",
    "IMG_SIZE = (224, 224)   # tuple: target_size untuk flow_from_directory\n",
    "IMG_SIDE = IMG_SIZE[0]  # integer untuk fungsi make_square\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Training\n",
    "TRAIN_EPOCHS = 5\n",
    "TRAIN_LEARNING_RATE = 0.0005\n",
    "\n",
    "# Fine-Tuning\n",
    "TUNING_EPOCHS = 10\n",
    "TUNING_LEARNING_RATE = 1e-5\n",
    "\n",
    "SPLIT_RATIO = {\n",
    "    \"train\": 0.8, \n",
    "    \"val\": 0.1, \n",
    "    \"test\": 0.1\n",
    "}\n",
    "\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"PARAMETER siap:\", IMG_SIZE, \"BATCH_SIZE=\", BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70476c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# STEP 4: Data generators\n",
    "# - train: augmentation + rescale\n",
    "# - val/test: hanya rescale\n",
    "# ==========================================\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valtest_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(PROCESSED_DIR, \"train\"),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_generator = valtest_datagen.flow_from_directory(\n",
    "    os.path.join(PROCESSED_DIR, \"val\"),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = valtest_datagen.flow_from_directory(\n",
    "    os.path.join(PROCESSED_DIR, \"test\"),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Generators siap:\")\n",
    "print(\" - train samples:\", train_generator.samples)\n",
    "print(\" - val samples:\", val_generator.samples)\n",
    "print(\" - test samples:\", test_generator.samples)\n",
    "print(\"Classes:\", train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f637c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# (Optional) print counts per class for sanity check\n",
    "# ==========================================\n",
    "\n",
    "print(\"\\nCounts per class (train):\")\n",
    "train_counts = Counter([os.path.split(f)[0] for f in train_generator.filenames])\n",
    "for cls, idx in train_generator.class_indices.items():\n",
    "    print(f\" - {cls}: {train_counts[cls]}\")\n",
    "\n",
    "print(\"\\nCounts per class (val):\")\n",
    "val_counts = Counter([os.path.split(f)[0] for f in val_generator.filenames])\n",
    "for cls, idx in val_generator.class_indices.items():\n",
    "    print(f\" - {cls}: {val_counts[cls]}\")\n",
    "\n",
    "print(\"\\nCounts per class (test):\")\n",
    "val_counts = Counter([os.path.split(f)[0] for f in test_generator.filenames])\n",
    "for cls, idx in val_generator.class_indices.items():\n",
    "    print(f\" - {cls}: {val_counts[cls]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ea134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# STEP 5: Build model (MobileNetV2 transfer learning)\n",
    "# ==========================================\n",
    "\n",
    "num_classes = train_generator.num_classes\n",
    "\n",
    "MODEL_NAME = \"MobileNetV2\"\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIDE, IMG_SIDE, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "preds = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "# freeze base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=TRAIN_LEARNING_RATE), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nModel siap. Jumlah kelas:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46804a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# STEP 6: Callbacks (recommended)\n",
    "# ==========================================\n",
    "\n",
    "checkpoint_path = os.path.join(MODEL_DIR, \"best_model.h5\")\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss', verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eb85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import tensorflow as tf\n",
    "\n",
    "class LiveTrainPlot(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.batch_count = []\n",
    "        self.loss = []\n",
    "        self.acc = []\n",
    "        self.step = 0\n",
    "        self.current_epoch = 1\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.step += 1\n",
    "        self.batch_count.append(self.step)\n",
    "        self.loss.append(logs.get('loss'))\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(13,5))\n",
    "\n",
    "        # ================= LOSS =================\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(self.batch_count, self.loss, color='red', label='Loss')\n",
    "\n",
    "        plt.text(0.01, 0.95, f'Current Epoch: {self.current_epoch}',\n",
    "                 transform=plt.gca().transAxes,\n",
    "                 fontsize=11, color='red', weight='bold')\n",
    "\n",
    "        plt.title('Loss (per batch)')\n",
    "        plt.xlabel('Batch')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # ================= ACCURACY =================\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(self.batch_count, self.acc, color='blue', label='Accuracy')\n",
    "\n",
    "        plt.text(0.01, 0.95, f'Current Epoch: {self.current_epoch}',\n",
    "                 transform=plt.gca().transAxes,\n",
    "                 fontsize=11, color='blue', weight='bold')\n",
    "\n",
    "        plt.title('Accuracy (per batch)')\n",
    "        plt.xlabel('Batch')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.current_epoch = epoch + 1\n",
    "\n",
    "\n",
    "liveplot = LiveTrainPlot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55460c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# STEP 7: Training\n",
    "# ==========================================\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=TRAIN_EPOCHS,\n",
    "    callbacks=[liveplot] + callbacks\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 8: Fine-tuning (fase kedua)\n",
    "# ==========================================\n",
    "\n",
    "# Unfreeze 50 layer terakhir dari base model\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile ulang dengan learning rate lebih kecil\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=TUNING_LEARNING_RATE),  # LR kecil untuk fine-tuning\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Latih ulang model (fine-tuning)\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=TUNING_EPOCHS,\n",
    "   callbacks=[liveplot] + callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# STEP 8: Save final model & metadata\n",
    "# ==========================================\n",
    "\n",
    "# --- GABUNGKAN HISTORY (fase 1 + fase 2) ---\n",
    "# agar grafik & statistik mencakup seluruh pelatihan\n",
    "combined_history = {}\n",
    "for key in history.history.keys():\n",
    "    combined_history[key] = history.history[key] + history_finetune.history.get(key, [])\n",
    "\n",
    "# --- Hitung rata-rata akurasi dari fase akhir (fine-tuning) ---\n",
    "train_acc_avg = np.mean(history_finetune.history.get('accuracy', history.history.get('accuracy', [-1])))\n",
    "val_acc_avg   = np.mean(history_finetune.history.get('val_accuracy', history.history.get('val_accuracy', [-1])))\n",
    "\n",
    "train_acc_int = int(train_acc_avg * 100)\n",
    "val_acc_int = int(val_acc_avg * 100)\n",
    "\n",
    "# create versioned folder like before\n",
    "pattern = re.compile(r\"model(\\d+)-(\\d+)-(\\d+)\")\n",
    "existing_dirs = [d for d in os.listdir(MODEL_DIR) if os.path.isdir(os.path.join(MODEL_DIR, d))]\n",
    "model_id = MODEL_ID\n",
    "versions = []\n",
    "for d in existing_dirs:\n",
    "    m = pattern.match(d)\n",
    "    if m and int(m.group(1)) == model_id:\n",
    "        versions.append(int(m.group(2)))\n",
    "next_version = max(versions) + 1 if versions else 1\n",
    "\n",
    "# --- Buat folder penyimpanan baru ---\n",
    "save_dir = os.path.join(MODEL_DIR, f\"model{model_id}-{next_version}-{train_acc_int}-{val_acc_int}\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# --- Simpan model final (setelah fine-tuning) ---\n",
    "final_model_path = os.path.join(save_dir, f\"model.h5\")\n",
    "model.save(final_model_path)\n",
    "\n",
    "# --- Simpan label kelas ---\n",
    "labels = {v: k for k, v in train_generator.class_indices.items()}\n",
    "with open(os.path.join(save_dir, \"labels.json\"), \"w\") as f:\n",
    "    json.dump(labels, f, indent=4)\n",
    "\n",
    "# --- Simpan ringkasan metadata model ---\n",
    "summary = {\n",
    "    \"model_id\": model_id,\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"version\": next_version,\n",
    "    \"train_acc_avg\": round(float(train_acc_avg) * 100, 2),\n",
    "    \"val_acc_avg\": round(float(val_acc_avg) * 100, 2),\n",
    "    \"epochs_phase1\": len(history.history.get('accuracy', [])),\n",
    "    \"epochs_phase2\": len(history_finetune.history.get('accuracy', [])),\n",
    "    \"model_path\": final_model_path\n",
    "}\n",
    "with open(os.path.join(save_dir, \"summary.json\"), \"w\") as f:\n",
    "    json.dump(summary, f, indent=4)\n",
    "\n",
    "def to_serializable(obj):\n",
    "    \"\"\"Konversi semua numpy type ke tipe Python biasa agar bisa di-dump ke JSON\"\"\"\n",
    "    if isinstance(obj, (np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    if isinstance(obj, (np.int32, np.int64)):\n",
    "        return int(obj)\n",
    "    if isinstance(obj, (np.ndarray, list)):\n",
    "        return [to_serializable(x) for x in obj]\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: to_serializable(v) for k, v in obj.items()}\n",
    "    return obj\n",
    "\n",
    "\n",
    "# --- Simpan riwayat pelatihan (fase 1, fase 2, dan gabungan) ---\n",
    "with open(os.path.join(save_dir, \"history_phase1.json\"), \"w\") as f:\n",
    "    json.dump(to_serializable(history.history), f, indent=4)\n",
    "\n",
    "with open(os.path.join(save_dir, \"history_finetune.json\"), \"w\") as f:\n",
    "    json.dump(to_serializable(history_finetune.history), f, indent=4)\n",
    "\n",
    "with open(os.path.join(save_dir, \"history_combined.json\"), \"w\") as f:\n",
    "    json.dump(to_serializable(combined_history), f, indent=4)\n",
    "\n",
    "\n",
    "print(f\"üìÅ Semua file metadata dan history disimpan di: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26034195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# STEP 9: Plot & save metrics (FINAL)\n",
    "# ==========================================\n",
    "\n",
    "# Gunakan combined_history dari STEP 8\n",
    "acc      = combined_history.get('accuracy', [])\n",
    "val_acc  = combined_history.get('val_accuracy', [])\n",
    "loss     = combined_history.get('loss', [])\n",
    "val_loss = combined_history.get('val_loss', [])\n",
    "\n",
    "epochs_range = range(1, len(acc) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# --- Plot Accuracy ---\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Accuracy', marker='o')\n",
    "plt.plot(epochs_range, val_acc, label='Val Accuracy', marker='s')\n",
    "plt.title(\"Training & Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# --- Plot Loss ---\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss', marker='o')\n",
    "plt.plot(epochs_range, val_loss, label='Val Loss', marker='s')\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- Simpan grafik ---\n",
    "metrics_path = os.path.join(save_dir, \"metrics.png\")\n",
    "plt.savefig(metrics_path)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"üìà Grafik akurasi & loss disimpan di: {metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b16ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# STEP 10: Evaluation (validation set)\n",
    "# ==========================================\n",
    "print(\"\\nüöÄ Evaluasi Model pada Validation Set...\")\n",
    "\n",
    "# --- Reset generator agar prediksi berurutan ---\n",
    "val_generator.reset()\n",
    "\n",
    "# --- Prediksi ---\n",
    "y_pred = model.predict(val_generator, verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# --- Label kelas ---\n",
    "class_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "# --- Classification Report ---\n",
    "print(\"\\nüìä Classification Report (Validation):\")\n",
    "report_val = classification_report(\n",
    "    y_true,\n",
    "    y_pred_classes,\n",
    "    target_names=class_labels,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred_classes,\n",
    "    target_names=class_labels,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# --- Simpan laporan evaluasi ke JSON ---\n",
    "eval_val_path = os.path.join(save_dir, \"evaluation_val.json\")\n",
    "with open(eval_val_path, \"w\") as f:\n",
    "    json.dump(report_val, f, indent=4)\n",
    "print(f\"‚úÖ Laporan evaluasi validasi disimpan: {eval_val_path}\")\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - Validation Set')\n",
    "\n",
    "# --- Simpan confusion matrix ---\n",
    "cm_val_path = os.path.join(save_dir, \"confusion_matrix_val.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_val_path)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"üß© Confusion matrix validasi disimpan di: {cm_val_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01780d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# STEP 11: Testing (test set)\n",
    "# ==========================================\n",
    "print(\"\\nüöÄ Evaluasi Model pada Test Set...\")\n",
    "\n",
    "# --- Reset generator ---\n",
    "test_generator.reset()\n",
    "\n",
    "# --- Evaluasi langsung ---\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=0)\n",
    "print(f\"\\nüìà Test Accuracy: {test_acc*100:.2f}%  |  Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# --- Prediksi ---\n",
    "y_pred_test = model.predict(test_generator, verbose=0)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_true_test = test_generator.classes\n",
    "\n",
    "# --- Label kelas ---\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# --- Classification Report ---\n",
    "print(\"\\nüìä Classification Report (Test):\")\n",
    "report_test = classification_report(\n",
    "    y_true_test,\n",
    "    y_pred_test_classes,\n",
    "    target_names=class_labels,\n",
    "    zero_division=0,\n",
    "    output_dict=True\n",
    ")\n",
    "print(classification_report(\n",
    "    y_true_test,\n",
    "    y_pred_test_classes,\n",
    "    target_names=class_labels,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# --- Simpan laporan evaluasi ke JSON ---\n",
    "eval_test_path = os.path.join(save_dir, \"evaluation_test.json\")\n",
    "with open(eval_test_path, \"w\") as f:\n",
    "    json.dump(report_test, f, indent=4)\n",
    "print(f\"‚úÖ Laporan evaluasi testing disimpan: {eval_test_path}\")\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm_test = confusion_matrix(y_true_test, y_pred_test_classes)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=class_labels,\n",
    "            yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - Test Set')\n",
    "\n",
    "# --- Simpan confusion matrix ---\n",
    "cm_test_path = os.path.join(save_dir, \"confusion_matrix_test.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_test_path)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(f\"üß© Confusion matrix testing disimpan di: {cm_test_path}\")\n",
    "\n",
    "# --- Simpan ringkasan hasil test ke summary.json ---\n",
    "summary[\"test_accuracy\"] = round(float(test_acc) * 100, 2)\n",
    "summary[\"test_loss\"] = round(float(test_loss), 4)\n",
    "\n",
    "with open(os.path.join(save_dir, \"summary.json\"), \"w\") as f:\n",
    "    json.dump(summary, f, indent=4)\n",
    "\n",
    "print(f\"üìò Summary diperbarui dengan hasil test: {os.path.join(save_dir, 'summary.json')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_roadmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
